Training DataLoader: total tokens: 10255324043 in 103 files
Validation DataLoader: total tokens: 100000000 in 1 files
DeMon Test:
  - Learning rate: 0.04
  - Momentum factor (mu): 0.95
  - Residual factor (beta): 0.95
  - Weight decay: 0
  - Sparsity: 0.5
  - Power iterations: 1
  - Epsilon: 1e-07
  - Tuned Newton-Schulz constants: False
  - Rank-r approximation method: power_iter
  - Newton-Schulz iterations: 5
  - Additional orthogonalization: False
Training:   0%|          | 0/3000 [00:00<?, ?it/s][rank0]:W0312 14:03:36.855000 1390 site-packages/torch/_inductor/utils.py:1762] [0/0] DeviceCopy in input program
[rank0]:W0312 14:03:46.346000 1390 site-packages/torch/_inductor/utils.py:1762] [0/0] DeviceCopy in input program
[rank0]:W0312 14:03:48.507000 1390 site-packages/torch/_inductor/utils.py:1762] [0/0] DeviceCopy in input program
[rank0]:W0312 14:03:49.295000 1390 site-packages/torch/_inductor/utils.py:1762] [0/0] DeviceCopy in input program
[rank0]:W0312 14:03:50.288000 1390 site-packages/torch/_inductor/utils.py:1762] [0/0] DeviceCopy in input program
[rank0]:W0312 14:03:51.097000 1390 site-packages/torch/_inductor/utils.py:1762] [0/0] DeviceCopy in input program
[rank0]:W0312 14:03:51.890000 1390 site-packages/torch/_inductor/utils.py:1762] [0/0] DeviceCopy in input program
[rank0]:W0312 14:03:52.662000 1390 site-packages/torch/_inductor/utils.py:1762] [0/0] DeviceCopy in input program
[rank0]:W0312 14:03:53.439000 1390 site-packages/torch/_inductor/utils.py:1762] [0/0] DeviceCopy in input program

step:0/3000 val_loss:10.8258 train_time:5ms step_avg:nanms
Training:   0%|          | 0/3000 [00:48<?, ?it/s, val_loss=10.8258]/opt/conda/envs/ptca/lib/python3.10/site-packages/torch/_inductor/compile_fx.py:236: UserWarning: TensorFloat32 tensor cores for float32 matrix multiplication available but not enabled. Consider setting `torch.set_float32_matmul_precision('high')` for better performance.
  warnings.warn(
Training: 100%|██████████| 3000/3000 [10:35<00:00,  4.72it/s, val_loss=5.6777]   
step:125/3000 val_loss:6.0023 train_time:19616ms step_avg:170.57ms
step:250/3000 val_loss:5.9461 train_time:41224ms step_avg:171.77ms
step:375/3000 val_loss:5.9138 train_time:62586ms step_avg:171.47ms
step:500/3000 val_loss:5.8830 train_time:84174ms step_avg:171.78ms
step:625/3000 val_loss:5.8475 train_time:105788ms step_avg:172.01ms
step:750/3000 val_loss:5.8226 train_time:127188ms step_avg:171.88ms
step:875/3000 val_loss:5.8044 train_time:148887ms step_avg:172.12ms
step:1000/3000 val_loss:5.7931 train_time:170590ms step_avg:172.31ms
step:1125/3000 val_loss:5.7889 train_time:192055ms step_avg:172.25ms
step:1250/3000 val_loss:5.7852 train_time:213749ms step_avg:172.38ms
step:1375/3000 val_loss:5.7862 train_time:235487ms step_avg:172.52ms
step:1500/3000 val_loss:5.7770 train_time:256933ms step_avg:172.44ms
step:1625/3000 val_loss:5.7786 train_time:278667ms step_avg:172.55ms
step:1750/3000 val_loss:5.7749 train_time:300411ms step_avg:172.65ms
step:1875/3000 val_loss:5.7713 train_time:321907ms step_avg:172.60ms
step:2000/3000 val_loss:5.7691 train_time:343638ms step_avg:172.68ms
step:2125/3000 val_loss:5.7670 train_time:365403ms step_avg:172.77ms
step:2250/3000 val_loss:5.7531 train_time:386948ms step_avg:172.74ms
step:2375/3000 val_loss:5.7395 train_time:408750ms step_avg:172.83ms
step:2500/3000 val_loss:5.7251 train_time:430563ms step_avg:172.92ms
step:2625/3000 val_loss:5.7096 train_time:452109ms step_avg:172.89ms
step:2750/3000 val_loss:5.6958 train_time:473867ms step_avg:172.94ms
step:2875/3000 val_loss:5.6850 train_time:495648ms step_avg:173.00ms
step:3000/3000 val_loss:5.6777 train_time:517203ms step_avg:172.98ms
Peak memory consumption: 33531 MiB
