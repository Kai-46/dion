Training DataLoader: total tokens: 10255324043 in 103 files
Validation DataLoader: total tokens: 100000000 in 1 files
DeMon Test:
  - Learning rate: 0.04
  - Momentum factor (mu): 0.95
  - Residual factor (beta): 0.95
  - Weight decay: 0
  - Sparsity: 0.5
  - Power iterations: 1
  - Epsilon: 1e-07
  - Tuned Newton-Schulz constants: True
  - Rank-r approximation method: power_iter
  - Newton-Schulz iterations: 10
  - Additional orthogonalization: False
Training:   0%|          | 0/3000 [00:00<?, ?it/s][rank0]:W0312 14:01:47.224000 1441 site-packages/torch/_inductor/utils.py:1762] [0/0] DeviceCopy in input program
[rank0]:W0312 14:01:59.664000 1441 site-packages/torch/_inductor/utils.py:1762] [0/0] DeviceCopy in input program
[rank0]:W0312 14:02:01.933000 1441 site-packages/torch/_inductor/utils.py:1762] [0/0] DeviceCopy in input program
[rank0]:W0312 14:02:02.759000 1441 site-packages/torch/_inductor/utils.py:1762] [0/0] DeviceCopy in input program
[rank0]:W0312 14:02:03.784000 1441 site-packages/torch/_inductor/utils.py:1762] [0/0] DeviceCopy in input program
[rank0]:W0312 14:02:04.589000 1441 site-packages/torch/_inductor/utils.py:1762] [0/0] DeviceCopy in input program
[rank0]:W0312 14:02:05.417000 1441 site-packages/torch/_inductor/utils.py:1762] [0/0] DeviceCopy in input program
[rank0]:W0312 14:02:06.189000 1441 site-packages/torch/_inductor/utils.py:1762] [0/0] DeviceCopy in input program
[rank0]:W0312 14:02:06.941000 1441 site-packages/torch/_inductor/utils.py:1762] [0/0] DeviceCopy in input program

step:0/3000 val_loss:10.8258 train_time:2ms step_avg:nanms
Training:   0%|          | 0/3000 [00:48<?, ?it/s, val_loss=10.8258]/opt/conda/envs/ptca/lib/python3.10/site-packages/torch/_inductor/compile_fx.py:236: UserWarning: TensorFloat32 tensor cores for float32 matrix multiplication available but not enabled. Consider setting `torch.set_float32_matmul_precision('high')` for better performance.
  warnings.warn(
Training: 100%|██████████| 3000/3000 [11:45<00:00,  4.25it/s, val_loss=5.6775]   
step:125/3000 val_loss:6.0015 train_time:22151ms step_avg:192.61ms
step:250/3000 val_loss:5.9459 train_time:46558ms step_avg:193.99ms
step:375/3000 val_loss:5.9128 train_time:70672ms step_avg:193.62ms
step:500/3000 val_loss:5.8800 train_time:95051ms step_avg:193.98ms
step:625/3000 val_loss:5.8442 train_time:119493ms step_avg:194.30ms
step:750/3000 val_loss:5.8206 train_time:143657ms step_avg:194.13ms
step:875/3000 val_loss:5.8030 train_time:168178ms step_avg:194.43ms
step:1000/3000 val_loss:5.7926 train_time:192728ms step_avg:194.67ms
step:1125/3000 val_loss:5.7892 train_time:216943ms step_avg:194.57ms
step:1250/3000 val_loss:5.7847 train_time:241485ms step_avg:194.75ms
step:1375/3000 val_loss:5.7866 train_time:266025ms step_avg:194.89ms
step:1500/3000 val_loss:5.7766 train_time:290271ms step_avg:194.81ms
step:1625/3000 val_loss:5.7786 train_time:314860ms step_avg:194.96ms
step:1750/3000 val_loss:5.7754 train_time:339438ms step_avg:195.08ms
step:1875/3000 val_loss:5.7710 train_time:363713ms step_avg:195.02ms
step:2000/3000 val_loss:5.7690 train_time:388306ms step_avg:195.13ms
step:2125/3000 val_loss:5.7672 train_time:412915ms step_avg:195.23ms
step:2250/3000 val_loss:5.7521 train_time:437216ms step_avg:195.19ms
step:2375/3000 val_loss:5.7385 train_time:461808ms step_avg:195.27ms
step:2500/3000 val_loss:5.7248 train_time:486426ms step_avg:195.35ms
step:2625/3000 val_loss:5.7092 train_time:510719ms step_avg:195.30ms
step:2750/3000 val_loss:5.6953 train_time:535323ms step_avg:195.37ms
step:2875/3000 val_loss:5.6847 train_time:559942ms step_avg:195.44ms
step:3000/3000 val_loss:5.6775 train_time:584244ms step_avg:195.40ms
Peak memory consumption: 33529 MiB
