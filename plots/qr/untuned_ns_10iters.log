Training DataLoader: total tokens: 10255324043 in 103 files
Validation DataLoader: total tokens: 100000000 in 1 files
DeMon Test:
  - Learning rate: 0.04
  - Momentum factor (mu): 0.95
  - Residual factor (beta): 0.95
  - Weight decay: 0
  - Sparsity: 0.5
  - Power iterations: 1
  - Epsilon: 1e-07
  - Tuned Newton-Schulz constants: False
  - Rank-r approximation method: power_iter
  - Newton-Schulz iterations: 10
  - Additional orthogonalization: False
Training:   0%|          | 0/3000 [00:00<?, ?it/s][rank0]:W0312 14:04:20.829000 1279 site-packages/torch/_inductor/utils.py:1762] [0/0] DeviceCopy in input program
[rank0]:W0312 14:04:31.864000 1279 site-packages/torch/_inductor/utils.py:1762] [0/0] DeviceCopy in input program
[rank0]:W0312 14:04:34.083000 1279 site-packages/torch/_inductor/utils.py:1762] [0/0] DeviceCopy in input program
[rank0]:W0312 14:04:34.869000 1279 site-packages/torch/_inductor/utils.py:1762] [0/0] DeviceCopy in input program
[rank0]:W0312 14:04:35.884000 1279 site-packages/torch/_inductor/utils.py:1762] [0/0] DeviceCopy in input program
[rank0]:W0312 14:04:36.735000 1279 site-packages/torch/_inductor/utils.py:1762] [0/0] DeviceCopy in input program
[rank0]:W0312 14:04:37.568000 1279 site-packages/torch/_inductor/utils.py:1762] [0/0] DeviceCopy in input program
[rank0]:W0312 14:04:38.385000 1279 site-packages/torch/_inductor/utils.py:1762] [0/0] DeviceCopy in input program
[rank0]:W0312 14:04:39.182000 1279 site-packages/torch/_inductor/utils.py:1762] [0/0] DeviceCopy in input program

step:0/3000 val_loss:10.8258 train_time:3ms step_avg:nanms
Training:   0%|          | 0/3000 [00:48<?, ?it/s, val_loss=10.8258]/opt/conda/envs/ptca/lib/python3.10/site-packages/torch/_inductor/compile_fx.py:236: UserWarning: TensorFloat32 tensor cores for float32 matrix multiplication available but not enabled. Consider setting `torch.set_float32_matmul_precision('high')` for better performance.
  warnings.warn(
Training: 100%|██████████| 3000/3000 [11:40<00:00,  4.28it/s, val_loss=5.6776]   
step:125/3000 val_loss:6.0026 train_time:21940ms step_avg:190.79ms
step:250/3000 val_loss:5.9458 train_time:46119ms step_avg:192.16ms
step:375/3000 val_loss:5.9130 train_time:70004ms step_avg:191.79ms
step:500/3000 val_loss:5.8804 train_time:94180ms step_avg:192.20ms
step:625/3000 val_loss:5.8443 train_time:118338ms step_avg:192.42ms
step:750/3000 val_loss:5.8200 train_time:142256ms step_avg:192.24ms
step:875/3000 val_loss:5.8029 train_time:166513ms step_avg:192.50ms
step:1000/3000 val_loss:5.7915 train_time:190776ms step_avg:192.70ms
step:1125/3000 val_loss:5.7879 train_time:214741ms step_avg:192.59ms
step:1250/3000 val_loss:5.7840 train_time:239020ms step_avg:192.76ms
step:1375/3000 val_loss:5.7859 train_time:263303ms step_avg:192.90ms
step:1500/3000 val_loss:5.7762 train_time:287279ms step_avg:192.80ms
step:1625/3000 val_loss:5.7780 train_time:311584ms step_avg:192.93ms
step:1750/3000 val_loss:5.7743 train_time:335882ms step_avg:193.04ms
step:1875/3000 val_loss:5.7710 train_time:359884ms step_avg:192.97ms
step:2000/3000 val_loss:5.7699 train_time:384252ms step_avg:193.09ms
step:2125/3000 val_loss:5.7676 train_time:408576ms step_avg:193.18ms
step:2250/3000 val_loss:5.7534 train_time:432593ms step_avg:193.12ms
step:2375/3000 val_loss:5.7400 train_time:456946ms step_avg:193.21ms
step:2500/3000 val_loss:5.7256 train_time:481313ms step_avg:193.30ms
step:2625/3000 val_loss:5.7100 train_time:505339ms step_avg:193.25ms
step:2750/3000 val_loss:5.6959 train_time:529694ms step_avg:193.32ms
step:2875/3000 val_loss:5.6852 train_time:554045ms step_avg:193.38ms
step:3000/3000 val_loss:5.6776 train_time:578098ms step_avg:193.34ms
Peak memory consumption: 33529 MiB
