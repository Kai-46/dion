Training DataLoader: total tokens: 10255324043 in 103 files
Validation DataLoader: total tokens: 100000000 in 1 files
DeMon optimizer initialized with:
  - Learning rate: 0.04
  - Momentum factor (mu): 0.95
  - Residual factor (beta): 0.95
  - Weight decay: 0
  - Sparsity: 0.2
  - Newton-Schulz iterations: -1
  - Power iterations: 4
  - Epsilon: 1e-07
  - Tuned Newton-Schulz constants: False
  - Rank-r approximation method: power_iter
Training:   0%|          | 0/3000 [00:00<?, ?it/s][rank0]:W0310 18:19:25.612000 1301 site-packages/torch/_inductor/utils.py:1614] [0/0] DeviceCopy in input program
[rank0]:W0310 18:19:39.622000 1301 site-packages/torch/_inductor/utils.py:1614] [0/0] DeviceCopy in input program
[rank0]:W0310 18:19:42.076000 1301 site-packages/torch/_inductor/utils.py:1614] [0/0] DeviceCopy in input program
[rank0]:W0310 18:19:42.957000 1301 site-packages/torch/_inductor/utils.py:1614] [0/0] DeviceCopy in input program
[rank0]:W0310 18:19:43.998000 1301 site-packages/torch/_inductor/utils.py:1614] [0/0] DeviceCopy in input program
[rank0]:W0310 18:19:44.865000 1301 site-packages/torch/_inductor/utils.py:1614] [0/0] DeviceCopy in input program
[rank0]:W0310 18:19:45.709000 1301 site-packages/torch/_inductor/utils.py:1614] [0/0] DeviceCopy in input program
[rank0]:W0310 18:19:46.559000 1301 site-packages/torch/_inductor/utils.py:1614] [0/0] DeviceCopy in input program
[rank0]:W0310 18:19:47.746000 1301 site-packages/torch/_inductor/utils.py:1614] [0/0] DeviceCopy in input program

step:0/3000 val_loss:10.8258 train_time:3ms step_avg:nanms
Training:   0%|          | 0/3000 [01:03<?, ?it/s, val_loss=10.8258]/opt/conda/envs/ptca/lib/python3.10/site-packages/torch/_inductor/compile_fx.py:200: UserWarning: TensorFloat32 tensor cores for float32 matrix multiplication available but not enabled. Consider setting `torch.set_float32_matmul_precision('high')` for better performance.
  warnings.warn(
Training: 100%|██████████| 3000/3000 [21:49<00:00,  2.29it/s, val_loss=3.3432]    
step:125/3000 val_loss:4.7252 train_time:44391ms step_avg:386.01ms
step:250/3000 val_loss:4.2006 train_time:92960ms step_avg:387.33ms
step:375/3000 val_loss:4.0095 train_time:141211ms step_avg:386.88ms
step:500/3000 val_loss:3.8916 train_time:189756ms step_avg:387.26ms
step:625/3000 val_loss:3.8151 train_time:238323ms step_avg:387.52ms
step:750/3000 val_loss:3.7598 train_time:286547ms step_avg:387.23ms
step:875/3000 val_loss:3.7127 train_time:335071ms step_avg:387.37ms
step:1000/3000 val_loss:3.6726 train_time:383607ms step_avg:387.48ms
step:1125/3000 val_loss:3.6437 train_time:431805ms step_avg:387.27ms
step:1250/3000 val_loss:3.6143 train_time:480351ms step_avg:387.38ms
step:1375/3000 val_loss:3.5939 train_time:528893ms step_avg:387.47ms
step:1500/3000 val_loss:3.5694 train_time:577108ms step_avg:387.32ms
step:1625/3000 val_loss:3.5519 train_time:625635ms step_avg:387.39ms
step:1750/3000 val_loss:3.5334 train_time:674149ms step_avg:387.44ms
step:1875/3000 val_loss:3.5175 train_time:722390ms step_avg:387.34ms
step:2000/3000 val_loss:3.5034 train_time:770908ms step_avg:387.39ms
step:2125/3000 val_loss:3.4898 train_time:819472ms step_avg:387.46ms
step:2250/3000 val_loss:3.4627 train_time:867710ms step_avg:387.37ms
step:2375/3000 val_loss:3.4394 train_time:916253ms step_avg:387.42ms
step:2500/3000 val_loss:3.4143 train_time:964772ms step_avg:387.46ms
step:2625/3000 val_loss:3.3906 train_time:1012969ms step_avg:387.37ms
step:2750/3000 val_loss:3.3706 train_time:1061495ms step_avg:387.41ms
step:2875/3000 val_loss:3.3534 train_time:1110033ms step_avg:387.45ms
step:3000/3000 val_loss:3.3432 train_time:1158216ms step_avg:387.36ms
Peak memory consumption: 33463 MiB
