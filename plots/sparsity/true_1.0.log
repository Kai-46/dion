Training DataLoader: total tokens: 10255324043 in 103 files
Validation DataLoader: total tokens: 100000000 in 1 files
DeMon optimizer initialized with:
  - Learning rate: 0.04
  - Momentum factor (mu): 0.95
  - Residual factor (beta): 0.95
  - Weight decay: 0
  - Sparsity: 1.0
  - Newton-Schulz iterations: -1
  - Power iterations: 1
  - Epsilon: 1e-07
  - Tuned Newton-Schulz constants: False
  - Rank-r approximation method: power_iter
Training:   0%|          | 0/3000 [00:00<?, ?it/s][rank0]:W0310 19:24:17.739000 1390 site-packages/torch/_inductor/utils.py:1614] [0/0] DeviceCopy in input program
[rank0]:W0310 19:24:28.333000 1390 site-packages/torch/_inductor/utils.py:1614] [0/0] DeviceCopy in input program
[rank0]:W0310 19:24:30.754000 1390 site-packages/torch/_inductor/utils.py:1614] [0/0] DeviceCopy in input program
[rank0]:W0310 19:24:31.647000 1390 site-packages/torch/_inductor/utils.py:1614] [0/0] DeviceCopy in input program
[rank0]:W0310 19:24:32.703000 1390 site-packages/torch/_inductor/utils.py:1614] [0/0] DeviceCopy in input program
[rank0]:W0310 19:24:33.608000 1390 site-packages/torch/_inductor/utils.py:1614] [0/0] DeviceCopy in input program
[rank0]:W0310 19:24:34.471000 1390 site-packages/torch/_inductor/utils.py:1614] [0/0] DeviceCopy in input program
[rank0]:W0310 19:24:35.325000 1390 site-packages/torch/_inductor/utils.py:1614] [0/0] DeviceCopy in input program
[rank0]:W0310 19:24:36.498000 1390 site-packages/torch/_inductor/utils.py:1614] [0/0] DeviceCopy in input program

step:0/3000 val_loss:10.8258 train_time:5ms step_avg:nanms
Training:   0%|          | 0/3000 [01:03<?, ?it/s, val_loss=10.8258]/opt/conda/envs/ptca/lib/python3.10/site-packages/torch/_inductor/compile_fx.py:200: UserWarning: TensorFloat32 tensor cores for float32 matrix multiplication available but not enabled. Consider setting `torch.set_float32_matmul_precision('high')` for better performance.
  warnings.warn(
Training: 100%|██████████| 3000/3000 [24:39<00:00,  2.03it/s, val_loss=3.3180]    
step:125/3000 val_loss:4.6374 train_time:50814ms step_avg:441.86ms
step:250/3000 val_loss:4.1320 train_time:106313ms step_avg:442.97ms
step:375/3000 val_loss:3.9564 train_time:161543ms step_avg:442.58ms
step:500/3000 val_loss:3.8478 train_time:217037ms step_avg:442.93ms
step:625/3000 val_loss:3.7750 train_time:272553ms step_avg:443.18ms
step:750/3000 val_loss:3.7229 train_time:327779ms step_avg:442.94ms
step:875/3000 val_loss:3.6791 train_time:383252ms step_avg:443.07ms
step:1000/3000 val_loss:3.6430 train_time:438712ms step_avg:443.14ms
step:1125/3000 val_loss:3.6146 train_time:493915ms step_avg:442.97ms
step:1250/3000 val_loss:3.5869 train_time:549350ms step_avg:443.02ms
step:1375/3000 val_loss:3.5675 train_time:604801ms step_avg:443.08ms
step:1500/3000 val_loss:3.5436 train_time:660014ms step_avg:442.96ms
step:1625/3000 val_loss:3.5302 train_time:715530ms step_avg:443.05ms
step:1750/3000 val_loss:3.5106 train_time:771026ms step_avg:443.12ms
step:1875/3000 val_loss:3.4956 train_time:826232ms step_avg:443.02ms
step:2000/3000 val_loss:3.4829 train_time:881736ms step_avg:443.08ms
step:2125/3000 val_loss:3.4701 train_time:937257ms step_avg:443.15ms
step:2250/3000 val_loss:3.4450 train_time:992475ms step_avg:443.07ms
step:2375/3000 val_loss:3.4181 train_time:1047989ms step_avg:443.12ms
step:2500/3000 val_loss:3.3927 train_time:1103533ms step_avg:443.19ms
step:2625/3000 val_loss:3.3684 train_time:1158766ms step_avg:443.12ms
step:2750/3000 val_loss:3.3467 train_time:1214289ms step_avg:443.17ms
step:2875/3000 val_loss:3.3288 train_time:1269807ms step_avg:443.21ms
step:3000/3000 val_loss:3.3180 train_time:1325033ms step_avg:443.15ms
Peak memory consumption: 33673 MiB
