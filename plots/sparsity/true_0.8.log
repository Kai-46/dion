Training DataLoader: total tokens: 10255324043 in 103 files
Validation DataLoader: total tokens: 100000000 in 1 files
DeMon optimizer initialized with:
  - Learning rate: 0.04
  - Momentum factor (mu): 0.95
  - Residual factor (beta): 0.95
  - Weight decay: 0
  - Sparsity: 0.8
  - Newton-Schulz iterations: -1
  - Power iterations: 1
  - Epsilon: 1e-07
  - Tuned Newton-Schulz constants: False
  - Rank-r approximation method: power_iter
Training:   0%|          | 0/3000 [00:00<?, ?it/s][rank0]:W0310 19:24:41.682000 1508 site-packages/torch/_inductor/utils.py:1614] [0/0] DeviceCopy in input program
[rank0]:W0310 19:24:49.330000 1508 site-packages/torch/_inductor/utils.py:1614] [0/0] DeviceCopy in input program
[rank0]:W0310 19:24:52.031000 1508 site-packages/torch/_inductor/utils.py:1614] [0/0] DeviceCopy in input program
[rank0]:W0310 19:24:52.966000 1508 site-packages/torch/_inductor/utils.py:1614] [0/0] DeviceCopy in input program
[rank0]:W0310 19:24:54.068000 1508 site-packages/torch/_inductor/utils.py:1614] [0/0] DeviceCopy in input program
[rank0]:W0310 19:24:54.955000 1508 site-packages/torch/_inductor/utils.py:1614] [0/0] DeviceCopy in input program
[rank0]:W0310 19:24:55.843000 1508 site-packages/torch/_inductor/utils.py:1614] [0/0] DeviceCopy in input program
[rank0]:W0310 19:24:56.759000 1508 site-packages/torch/_inductor/utils.py:1614] [0/0] DeviceCopy in input program
[rank0]:W0310 19:24:58.019000 1508 site-packages/torch/_inductor/utils.py:1614] [0/0] DeviceCopy in input program

step:0/3000 val_loss:10.8258 train_time:3ms step_avg:nanms
Training:   0%|          | 0/3000 [01:04<?, ?it/s, val_loss=10.8258]/opt/conda/envs/ptca/lib/python3.10/site-packages/torch/_inductor/compile_fx.py:200: UserWarning: TensorFloat32 tensor cores for float32 matrix multiplication available but not enabled. Consider setting `torch.set_float32_matmul_precision('high')` for better performance.
  warnings.warn(
Training: 100%|██████████| 3000/3000 [21:54<00:00,  2.28it/s, val_loss=3.3085]    
step:125/3000 val_loss:4.6792 train_time:44544ms step_avg:387.34ms
step:250/3000 val_loss:4.1218 train_time:93256ms step_avg:388.57ms
step:375/3000 val_loss:3.9399 train_time:141674ms step_avg:388.15ms
step:500/3000 val_loss:3.8310 train_time:190350ms step_avg:388.47ms
step:625/3000 val_loss:3.7605 train_time:238996ms step_avg:388.61ms
step:750/3000 val_loss:3.7074 train_time:287394ms step_avg:388.37ms
step:875/3000 val_loss:3.6638 train_time:336058ms step_avg:388.51ms
step:1000/3000 val_loss:3.6299 train_time:384725ms step_avg:388.61ms
step:1125/3000 val_loss:3.6003 train_time:433124ms step_avg:388.45ms
step:1250/3000 val_loss:3.5745 train_time:481782ms step_avg:388.53ms
step:1375/3000 val_loss:3.5539 train_time:530419ms step_avg:388.59ms
step:1500/3000 val_loss:3.5329 train_time:578805ms step_avg:388.46ms
step:1625/3000 val_loss:3.5176 train_time:627472ms step_avg:388.53ms
step:1750/3000 val_loss:3.4998 train_time:676152ms step_avg:388.59ms
step:1875/3000 val_loss:3.4846 train_time:724534ms step_avg:388.49ms
step:2000/3000 val_loss:3.4727 train_time:773182ms step_avg:388.53ms
step:2125/3000 val_loss:3.4600 train_time:821903ms step_avg:388.61ms
step:2250/3000 val_loss:3.4333 train_time:870298ms step_avg:388.53ms
step:2375/3000 val_loss:3.4083 train_time:919055ms step_avg:388.61ms
step:2500/3000 val_loss:3.3830 train_time:967799ms step_avg:388.67ms
step:2625/3000 val_loss:3.3584 train_time:1016210ms step_avg:388.61ms
step:2750/3000 val_loss:3.3371 train_time:1064928ms step_avg:388.66ms
step:2875/3000 val_loss:3.3192 train_time:1113654ms step_avg:388.71ms
step:3000/3000 val_loss:3.3085 train_time:1162077ms step_avg:388.65ms
Peak memory consumption: 33613 MiB
