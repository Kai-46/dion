Training DataLoader: total tokens: 10255324043 in 103 files
Validation DataLoader: total tokens: 100000000 in 1 files
DeMon optimizer initialized with:
  - Learning rate: 0.04
  - Momentum factor (mu): 0.95
  - Residual factor (beta): 0.95
  - Weight decay: 0
  - Sparsity: 0.2
  - Newton-Schulz iterations: -1
  - Power iterations: 8
  - Epsilon: 1e-07
  - Tuned Newton-Schulz constants: False
  - Rank-r approximation method: power_iter
Training:   0%|          | 0/3000 [00:00<?, ?it/s][rank0]:W0310 19:15:03.660000 1417 site-packages/torch/_inductor/utils.py:1614] [0/0] DeviceCopy in input program
[rank0]:W0310 19:15:11.044000 1417 site-packages/torch/_inductor/utils.py:1614] [0/0] DeviceCopy in input program
[rank0]:W0310 19:15:13.380000 1417 site-packages/torch/_inductor/utils.py:1614] [0/0] DeviceCopy in input program
[rank0]:W0310 19:15:14.251000 1417 site-packages/torch/_inductor/utils.py:1614] [0/0] DeviceCopy in input program
[rank0]:W0310 19:15:15.281000 1417 site-packages/torch/_inductor/utils.py:1614] [0/0] DeviceCopy in input program
[rank0]:W0310 19:15:16.086000 1417 site-packages/torch/_inductor/utils.py:1614] [0/0] DeviceCopy in input program
[rank0]:W0310 19:15:16.978000 1417 site-packages/torch/_inductor/utils.py:1614] [0/0] DeviceCopy in input program
[rank0]:W0310 19:15:17.812000 1417 site-packages/torch/_inductor/utils.py:1614] [0/0] DeviceCopy in input program
[rank0]:W0310 19:15:19.025000 1417 site-packages/torch/_inductor/utils.py:1614] [0/0] DeviceCopy in input program

step:0/3000 val_loss:10.8258 train_time:3ms step_avg:nanms
Training:   0%|          | 0/3000 [01:04<?, ?it/s, val_loss=10.8258]/opt/conda/envs/ptca/lib/python3.10/site-packages/torch/_inductor/compile_fx.py:200: UserWarning: TensorFloat32 tensor cores for float32 matrix multiplication available but not enabled. Consider setting `torch.set_float32_matmul_precision('high')` for better performance.
  warnings.warn(
Training: 100%|██████████| 3000/3000 [33:30<00:00,  1.49it/s, val_loss=3.3464]    
step:125/3000 val_loss:4.7533 train_time:71339ms step_avg:620.34ms
step:250/3000 val_loss:4.2133 train_time:149105ms step_avg:621.27ms
step:375/3000 val_loss:4.0209 train_time:226642ms step_avg:620.94ms
step:500/3000 val_loss:3.9004 train_time:304423ms step_avg:621.27ms
step:625/3000 val_loss:3.8230 train_time:382221ms step_avg:621.50ms
step:750/3000 val_loss:3.7676 train_time:459764ms step_avg:621.30ms
step:875/3000 val_loss:3.7168 train_time:537566ms step_avg:621.46ms
step:1000/3000 val_loss:3.6757 train_time:615323ms step_avg:621.54ms
step:1125/3000 val_loss:3.6469 train_time:692842ms step_avg:621.38ms
step:1250/3000 val_loss:3.6178 train_time:770597ms step_avg:621.45ms
step:1375/3000 val_loss:3.5987 train_time:848343ms step_avg:621.50ms
step:1500/3000 val_loss:3.5700 train_time:925873ms step_avg:621.39ms
step:1625/3000 val_loss:3.5557 train_time:1003635ms step_avg:621.45ms
step:1750/3000 val_loss:3.5354 train_time:1081372ms step_avg:621.48ms
step:1875/3000 val_loss:3.5212 train_time:1158932ms step_avg:621.41ms
step:2000/3000 val_loss:3.5069 train_time:1236684ms step_avg:621.45ms
step:2125/3000 val_loss:3.4928 train_time:1314450ms step_avg:621.49ms
step:2250/3000 val_loss:3.4659 train_time:1391988ms step_avg:621.42ms
step:2375/3000 val_loss:3.4417 train_time:1469736ms step_avg:621.45ms
step:2500/3000 val_loss:3.4170 train_time:1547508ms step_avg:621.49ms
step:2625/3000 val_loss:3.3938 train_time:1625069ms step_avg:621.44ms
step:2750/3000 val_loss:3.3734 train_time:1702848ms step_avg:621.48ms
step:2875/3000 val_loss:3.3564 train_time:1780583ms step_avg:621.49ms
step:3000/3000 val_loss:3.3464 train_time:1858121ms step_avg:621.45ms
Peak memory consumption: 33457 MiB
