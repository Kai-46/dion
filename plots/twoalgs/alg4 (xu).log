Training DataLoader: total tokens: 10255324043 in 103 files
Validation DataLoader: total tokens: 100000000 in 1 files
DeMon2 optimizer initialized with:
  - Learning rate: 0.04
  - Momentum factor (mu): 0.95
  - Residual factor (beta): 0.95
  - Weight decay: 0
  - Sparsity: 0.5
  - Newton-Schulz iterations: -1
  - Power iterations: 1
  - Epsilon: 1e-07
  - Tuned Newton-Schulz constants: False
  - Rank-r approximation method: power_iter
Training:   0%|          | 0/3000 [00:00<?, ?it/s][rank0]:W0312 14:09:22.513000 1388 site-packages/torch/_inductor/utils.py:1762] [0/0] DeviceCopy in input program
[rank0]:W0312 14:09:33.507000 1388 site-packages/torch/_inductor/utils.py:1762] [0/0] DeviceCopy in input program
[rank0]:W0312 14:09:35.797000 1388 site-packages/torch/_inductor/utils.py:1762] [0/0] DeviceCopy in input program
[rank0]:W0312 14:09:36.623000 1388 site-packages/torch/_inductor/utils.py:1762] [0/0] DeviceCopy in input program
[rank0]:W0312 14:09:37.674000 1388 site-packages/torch/_inductor/utils.py:1762] [0/0] DeviceCopy in input program
[rank0]:W0312 14:09:38.504000 1388 site-packages/torch/_inductor/utils.py:1762] [0/0] DeviceCopy in input program
[rank0]:W0312 14:09:39.362000 1388 site-packages/torch/_inductor/utils.py:1762] [0/0] DeviceCopy in input program
[rank0]:W0312 14:09:40.157000 1388 site-packages/torch/_inductor/utils.py:1762] [0/0] DeviceCopy in input program
[rank0]:W0312 14:09:40.944000 1388 site-packages/torch/_inductor/utils.py:1762] [0/0] DeviceCopy in input program

step:0/3000 val_loss:10.8258 train_time:3ms step_avg:nanms
Training:   0%|          | 0/3000 [00:48<?, ?it/s, val_loss=10.8258]/opt/conda/envs/ptca/lib/python3.10/site-packages/torch/_inductor/compile_fx.py:236: UserWarning: TensorFloat32 tensor cores for float32 matrix multiplication available but not enabled. Consider setting `torch.set_float32_matmul_precision('high')` for better performance.
  warnings.warn(
Training: 100%|██████████| 3000/3000 [16:38<00:00,  3.01it/s, val_loss=3.4999]   
step:125/3000 val_loss:4.9881 train_time:33761ms step_avg:293.57ms
step:250/3000 val_loss:4.4411 train_time:70701ms step_avg:294.59ms
step:375/3000 val_loss:4.2473 train_time:107404ms step_avg:294.26ms
step:500/3000 val_loss:4.1313 train_time:144367ms step_avg:294.63ms
step:625/3000 val_loss:4.0523 train_time:181318ms step_avg:294.83ms
step:750/3000 val_loss:3.9888 train_time:218039ms step_avg:294.65ms
step:875/3000 val_loss:3.9390 train_time:254979ms step_avg:294.77ms
step:1000/3000 val_loss:3.8904 train_time:291923ms step_avg:294.87ms
step:1125/3000 val_loss:3.8567 train_time:328645ms step_avg:294.75ms
step:1250/3000 val_loss:3.8284 train_time:365602ms step_avg:294.84ms
step:1375/3000 val_loss:3.8028 train_time:402534ms step_avg:294.90ms
step:1500/3000 val_loss:3.7746 train_time:439272ms step_avg:294.81ms
step:1625/3000 val_loss:3.7519 train_time:476214ms step_avg:294.87ms
step:1750/3000 val_loss:3.7360 train_time:513155ms step_avg:294.92ms
step:1875/3000 val_loss:3.7070 train_time:549859ms step_avg:294.83ms
step:2000/3000 val_loss:3.6998 train_time:586802ms step_avg:294.88ms
step:2125/3000 val_loss:3.6838 train_time:623751ms step_avg:294.92ms
step:2250/3000 val_loss:3.6439 train_time:660473ms step_avg:294.85ms
step:2375/3000 val_loss:3.6132 train_time:697414ms step_avg:294.89ms
step:2500/3000 val_loss:3.5771 train_time:734392ms step_avg:294.94ms
step:2625/3000 val_loss:3.5506 train_time:771102ms step_avg:294.88ms
step:2750/3000 val_loss:3.5268 train_time:808075ms step_avg:294.92ms
step:2875/3000 val_loss:3.5088 train_time:845027ms step_avg:294.95ms
step:3000/3000 val_loss:3.4999 train_time:881740ms step_avg:294.90ms
Peak memory consumption: 33530 MiB
