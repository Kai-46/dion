{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5602bd31",
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "\n",
    "wandb.login()\n",
    "\n",
    "api = wandb.Api()\n",
    "\n",
    "project_name = \"dion\"  # Replace with your project name\n",
    "entity_name = \"natalieabreu\"  # Replace with your wandb entity/username\n",
    "runs = api.runs(f\"{entity_name}/{project_name}\")\n",
    "runs = [run for run in runs if run.state == \"finished\"]\n",
    "\n",
    "for run in runs:\n",
    "    print(f\"Run ID: {run.id}, Name: {run.name}, State: {run.state}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d9f0add",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def plot(runs):\n",
    "    large_font = 14\n",
    "    small_font = 12\n",
    "    plt.rc(\"xtick\", labelsize=small_font)\n",
    "    plt.rc(\"ytick\", labelsize=small_font)\n",
    "    plt.rc(\"axes\", labelsize=large_font)\n",
    "    plt.rc(\"legend\", fontsize=large_font)\n",
    "\n",
    "    labels = {\n",
    "        \"dion_True\": \"Dion+Adam\",\n",
    "        \"dion_False\": \"Dion+Lion\",\n",
    "        \"muon_True\": \"Muon+Adam\",\n",
    "        \"muon_False\": \"Muon+Lion\",\n",
    "    }\n",
    "\n",
    "    # Iterate through each run in lowest_loss_runs\n",
    "    for _, row in runs.iterrows():\n",
    "        run_id = row[\"Run ID\"]\n",
    "        run = api.run(f\"{entity_name}/{project_name}/{run_id}\")\n",
    "        history = run.history(keys=[\"step\", \"val/loss\"])\n",
    "\n",
    "        # Plot step vs val/loss\n",
    "        lbl_key = f\"{row['Optimizer']}_{row['Adam for scalar']}\"\n",
    "        plt.plot(\n",
    "            history[\"step\"],\n",
    "            history[\"val/loss\"],\n",
    "            label=f\"{labels.get(lbl_key, 'Unknown')}\",\n",
    "        )\n",
    "\n",
    "    plt.xscale(\"log\")\n",
    "    plt.yscale(\"log\")\n",
    "\n",
    "    plt.gca().yaxis.set_minor_locator(plt.NullLocator())\n",
    "    plt.gca().xaxis.set_minor_locator(plt.NullLocator())\n",
    "\n",
    "    yticks = np.arange(3, 4.1, 0.2)\n",
    "    plt.yticks(yticks)\n",
    "    plt.gca().yaxis.set_major_formatter(\n",
    "        plt.FuncFormatter(lambda x, _: \"{:.1f}\".format(x))\n",
    "    )\n",
    "    plt.ylim(3, 4.1)\n",
    "\n",
    "    xticks = np.arange(0, 3.1e3, 5e2)\n",
    "    plt.xticks(xticks)\n",
    "    plt.gca().xaxis.set_major_formatter(\n",
    "        plt.FuncFormatter(lambda x, _: \"{:.0f}\".format(x))\n",
    "    )\n",
    "\n",
    "    plt.grid(axis=\"both\")\n",
    "    plt.xlabel(\"Step\")\n",
    "    plt.ylabel(\"Validation Loss\")\n",
    "    # plt.title(\"Step vs Validation Loss for Lowest Loss Runs\")\n",
    "    plt.legend()\n",
    "    plt.savefig(\"lion_vs_adam.pdf\", bbox_inches=\"tight\", format=\"pdf\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afe21889",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Extract relevant information from runs\n",
    "data = []\n",
    "for run in runs:\n",
    "    config = run.config  # Access the run's configuration\n",
    "    data.append(\n",
    "        {\n",
    "            \"Run ID\": run.id,\n",
    "            \"Optimizer\": config.get(\"optimizer\", None),\n",
    "            \"Learning Rate\": config.get(\"lr\", None),\n",
    "            \"Num Iterations\": config.get(\"num_iterations\", None),\n",
    "            \"LR Schedule\": config.get(\"lr_schedule\", None),\n",
    "            \"Mu\": config.get(\"mu\", 0.95),\n",
    "            \"Weight Decay\": config.get(\"weight_decay\", 0),\n",
    "            \"Sparsity\": config.get(\"sparsity\", 1),\n",
    "            \"Loss\": run.summary.get(\"val/loss\", None),\n",
    "            \"Batch size\": config.get(\"batch_size\", None),\n",
    "            \"Training set\": config.get(\"input_bin\", None),\n",
    "            \"Adam for scalar\": config.get(\"use_adam_for_scalar\", True),\n",
    "        }\n",
    "    )\n",
    "\n",
    "# Create a pandas DataFrame\n",
    "runs_df = pd.DataFrame(data)\n",
    "\n",
    "# Display the DataFrame\n",
    "print(runs_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b9b4ee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "bsz = 1024\n",
    "sparsity = 1\n",
    "num_iterations = 3000\n",
    "optimizers = [\"muon\", \"dion\"]\n",
    "\n",
    "# Filter the DataFrame based on the specified criteria\n",
    "filtered_df = runs_df[\n",
    "    (runs_df[\"Batch size\"] == bsz)\n",
    "    & (runs_df[\"Sparsity\"] == sparsity)\n",
    "    & (runs_df[\"Num Iterations\"] == num_iterations)\n",
    "    & (runs_df[\"Optimizer\"].isin(optimizers))\n",
    "]\n",
    "\n",
    "print(filtered_df[\"Adam for scalar\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99fd32e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped = filtered_df.groupby([\"Optimizer\", \"Adam for scalar\"])\n",
    "\n",
    "# Get the row with the lowest loss for each group\n",
    "lowest_loss_per_group = grouped.apply(lambda x: x.loc[x[\"Loss\"].idxmin()])\n",
    "\n",
    "# Display the results\n",
    "print(lowest_loss_per_group)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51052527",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(lowest_loss_per_group)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
