Training DataLoader: total tokens: 10255324043 in 103 files
Validation DataLoader: total tokens: 100000000 in 1 files
DeMon optimizer initialized with:
  - Learning rate: 0.04
  - Momentum factor (mu): 0.95
  - Residual factor (beta): 0.95
  - Weight decay: 0
  - Sparsity: 0.2
  - Newton-Schulz iterations: -1
  - Power iterations: 4
  - Epsilon: 1e-07
  - Tuned Newton-Schulz constants: False
  - Rank-r approximation method: power_iter
Training:   0%|          | 0/3000 [00:00<?, ?it/s][rank0]:W0310 18:22:34.233000 1364 site-packages/torch/_inductor/utils.py:1614] [0/0] DeviceCopy in input program
[rank0]:W0310 18:22:45.232000 1364 site-packages/torch/_inductor/utils.py:1614] [0/0] DeviceCopy in input program
[rank0]:W0310 18:22:47.694000 1364 site-packages/torch/_inductor/utils.py:1614] [0/0] DeviceCopy in input program
[rank0]:W0310 18:22:48.553000 1364 site-packages/torch/_inductor/utils.py:1614] [0/0] DeviceCopy in input program
[rank0]:W0310 18:22:49.597000 1364 site-packages/torch/_inductor/utils.py:1614] [0/0] DeviceCopy in input program
[rank0]:W0310 18:22:50.478000 1364 site-packages/torch/_inductor/utils.py:1614] [0/0] DeviceCopy in input program
[rank0]:W0310 18:22:51.362000 1364 site-packages/torch/_inductor/utils.py:1614] [0/0] DeviceCopy in input program
[rank0]:W0310 18:22:52.216000 1364 site-packages/torch/_inductor/utils.py:1614] [0/0] DeviceCopy in input program
[rank0]:W0310 18:22:53.415000 1364 site-packages/torch/_inductor/utils.py:1614] [0/0] DeviceCopy in input program

step:0/3000 val_loss:10.8258 train_time:3ms step_avg:nanms
Training:   0%|          | 0/3000 [01:03<?, ?it/s, val_loss=10.8258]/opt/conda/envs/ptca/lib/python3.10/site-packages/torch/_inductor/compile_fx.py:200: UserWarning: TensorFloat32 tensor cores for float32 matrix multiplication available but not enabled. Consider setting `torch.set_float32_matmul_precision('high')` for better performance.
  warnings.warn(
Training: 100%|██████████| 3000/3000 [21:45<00:00,  2.30it/s, val_loss=3.3410]    
step:125/3000 val_loss:4.7658 train_time:44283ms step_avg:385.07ms
step:250/3000 val_loss:4.2150 train_time:92718ms step_avg:386.33ms
step:375/3000 val_loss:4.0114 train_time:140833ms step_avg:385.84ms
step:500/3000 val_loss:3.8976 train_time:189183ms step_avg:386.09ms
step:625/3000 val_loss:3.8170 train_time:237541ms step_avg:386.24ms
step:750/3000 val_loss:3.7627 train_time:285638ms step_avg:386.00ms
step:875/3000 val_loss:3.7156 train_time:334009ms step_avg:386.14ms
step:1000/3000 val_loss:3.6731 train_time:382363ms step_avg:386.22ms
step:1125/3000 val_loss:3.6447 train_time:430467ms step_avg:386.07ms
step:1250/3000 val_loss:3.6148 train_time:478820ms step_avg:386.15ms
step:1375/3000 val_loss:3.5950 train_time:527181ms step_avg:386.21ms
step:1500/3000 val_loss:3.5746 train_time:575265ms step_avg:386.08ms
step:1625/3000 val_loss:3.5543 train_time:623606ms step_avg:386.13ms
step:1750/3000 val_loss:3.5346 train_time:671915ms step_avg:386.16ms
step:1875/3000 val_loss:3.5191 train_time:720008ms step_avg:386.06ms
step:2000/3000 val_loss:3.5039 train_time:768402ms step_avg:386.13ms
step:2125/3000 val_loss:3.4903 train_time:816750ms step_avg:386.17ms
step:2250/3000 val_loss:3.4625 train_time:864842ms step_avg:386.09ms
step:2375/3000 val_loss:3.4385 train_time:913206ms step_avg:386.13ms
step:2500/3000 val_loss:3.4135 train_time:961572ms step_avg:386.17ms
step:2625/3000 val_loss:3.3897 train_time:1009649ms step_avg:386.10ms
step:2750/3000 val_loss:3.3686 train_time:1058002ms step_avg:386.13ms
step:2875/3000 val_loss:3.3513 train_time:1106379ms step_avg:386.17ms
step:3000/3000 val_loss:3.3410 train_time:1154468ms step_avg:386.11ms
Peak memory consumption: 33457 MiB
