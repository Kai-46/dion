Training DataLoader: total tokens: 10255324043 in 103 files
Validation DataLoader: total tokens: 100000000 in 1 files
DeMon Test:
  - Learning rate: 0.04
  - Momentum factor (mu): 0.95
  - Residual factor (beta): 0.95
  - Weight decay: 0
  - Sparsity: 0.5
  - Power iterations: 1
  - Epsilon: 1e-07
  - Tuned Newton-Schulz constants: True
  - Rank-r approximation method: power_iter
  - Newton-Schulz iterations: 5
  - Additional orthogonalization: False
Training:   0%|          | 0/3000 [00:00<?, ?it/s][rank0]:W0312 14:01:44.897000 1360 site-packages/torch/_inductor/utils.py:1762] [0/0] DeviceCopy in input program
[rank0]:W0312 14:01:52.941000 1360 site-packages/torch/_inductor/utils.py:1762] [0/0] DeviceCopy in input program
[rank0]:W0312 14:01:55.116000 1360 site-packages/torch/_inductor/utils.py:1762] [0/0] DeviceCopy in input program
[rank0]:W0312 14:01:55.886000 1360 site-packages/torch/_inductor/utils.py:1762] [0/0] DeviceCopy in input program
[rank0]:W0312 14:01:56.901000 1360 site-packages/torch/_inductor/utils.py:1762] [0/0] DeviceCopy in input program
[rank0]:W0312 14:01:57.717000 1360 site-packages/torch/_inductor/utils.py:1762] [0/0] DeviceCopy in input program
[rank0]:W0312 14:01:58.502000 1360 site-packages/torch/_inductor/utils.py:1762] [0/0] DeviceCopy in input program
[rank0]:W0312 14:01:59.286000 1360 site-packages/torch/_inductor/utils.py:1762] [0/0] DeviceCopy in input program
[rank0]:W0312 14:02:00.084000 1360 site-packages/torch/_inductor/utils.py:1762] [0/0] DeviceCopy in input program

step:0/3000 val_loss:10.8258 train_time:3ms step_avg:nanms
Training:   0%|          | 0/3000 [00:47<?, ?it/s, val_loss=10.8258]/opt/conda/envs/ptca/lib/python3.10/site-packages/torch/_inductor/compile_fx.py:236: UserWarning: TensorFloat32 tensor cores for float32 matrix multiplication available but not enabled. Consider setting `torch.set_float32_matmul_precision('high')` for better performance.
  warnings.warn(
Training: 100%|██████████| 3000/3000 [10:40<00:00,  4.68it/s, val_loss=5.6780]   
step:125/3000 val_loss:6.0030 train_time:19590ms step_avg:170.35ms
step:250/3000 val_loss:5.9471 train_time:41215ms step_avg:171.73ms
step:375/3000 val_loss:5.9140 train_time:62531ms step_avg:171.32ms
step:500/3000 val_loss:5.8827 train_time:84134ms step_avg:171.70ms
step:625/3000 val_loss:5.8471 train_time:105717ms step_avg:171.90ms
step:750/3000 val_loss:5.8230 train_time:127084ms step_avg:171.73ms
step:875/3000 val_loss:5.8053 train_time:148746ms step_avg:171.96ms
step:1000/3000 val_loss:5.7944 train_time:170441ms step_avg:172.16ms
step:1125/3000 val_loss:5.7901 train_time:191902ms step_avg:172.11ms
step:1250/3000 val_loss:5.7861 train_time:213632ms step_avg:172.28ms
step:1375/3000 val_loss:5.7870 train_time:235393ms step_avg:172.45ms
step:1500/3000 val_loss:5.7778 train_time:256873ms step_avg:172.40ms
step:1625/3000 val_loss:5.7787 train_time:278627ms step_avg:172.52ms
step:1750/3000 val_loss:5.7746 train_time:300393ms step_avg:172.64ms
step:1875/3000 val_loss:5.7709 train_time:321840ms step_avg:172.57ms
step:2000/3000 val_loss:5.7696 train_time:343608ms step_avg:172.67ms
step:2125/3000 val_loss:5.7668 train_time:365415ms step_avg:172.77ms
step:2250/3000 val_loss:5.7524 train_time:386927ms step_avg:172.74ms
step:2375/3000 val_loss:5.7390 train_time:408742ms step_avg:172.83ms
step:2500/3000 val_loss:5.7251 train_time:430564ms step_avg:172.92ms
step:2625/3000 val_loss:5.7096 train_time:452041ms step_avg:172.86ms
step:2750/3000 val_loss:5.6957 train_time:473830ms step_avg:172.93ms
step:2875/3000 val_loss:5.6852 train_time:495658ms step_avg:173.00ms
step:3000/3000 val_loss:5.6780 train_time:517155ms step_avg:172.96ms
Peak memory consumption: 33531 MiB
