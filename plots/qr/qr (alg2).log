Training DataLoader: total tokens: 10255324043 in 103 files
Validation DataLoader: total tokens: 100000000 in 1 files
DeMon Test:
  - Learning rate: 0.04
  - Momentum factor (mu): 0.95
  - Residual factor (beta): 0.95
  - Weight decay: 0
  - Sparsity: 0.5
  - Power iterations: 1
  - Epsilon: 1e-07
  - Tuned Newton-Schulz constants: False
  - Rank-r approximation method: power_iter
  - Newton-Schulz iterations: -1
  - Additional orthogonalization: False
Training:   0%|          | 0/3000 [00:00<?, ?it/s][rank0]:W0312 14:02:42.325000 1357 site-packages/torch/_inductor/utils.py:1762] [0/0] DeviceCopy in input program
[rank0]:W0312 14:02:50.379000 1357 site-packages/torch/_inductor/utils.py:1762] [0/0] DeviceCopy in input program
[rank0]:W0312 14:02:52.833000 1357 site-packages/torch/_inductor/utils.py:1762] [0/0] DeviceCopy in input program
[rank0]:W0312 14:02:53.670000 1357 site-packages/torch/_inductor/utils.py:1762] [0/0] DeviceCopy in input program
[rank0]:W0312 14:02:54.694000 1357 site-packages/torch/_inductor/utils.py:1762] [0/0] DeviceCopy in input program
[rank0]:W0312 14:02:55.602000 1357 site-packages/torch/_inductor/utils.py:1762] [0/0] DeviceCopy in input program
[rank0]:W0312 14:02:56.480000 1357 site-packages/torch/_inductor/utils.py:1762] [0/0] DeviceCopy in input program
[rank0]:W0312 14:02:57.341000 1357 site-packages/torch/_inductor/utils.py:1762] [0/0] DeviceCopy in input program
[rank0]:W0312 14:02:58.192000 1357 site-packages/torch/_inductor/utils.py:1762] [0/0] DeviceCopy in input program

step:0/3000 val_loss:10.8258 train_time:3ms step_avg:nanms
Training:   0%|          | 0/3000 [00:48<?, ?it/s, val_loss=10.8258]/opt/conda/envs/ptca/lib/python3.10/site-packages/torch/_inductor/compile_fx.py:236: UserWarning: TensorFloat32 tensor cores for float32 matrix multiplication available but not enabled. Consider setting `torch.set_float32_matmul_precision('high')` for better performance.
  warnings.warn(
Training: 100%|██████████| 3000/3000 [16:39<00:00,  3.00it/s, val_loss=3.3055]   
step:125/3000 val_loss:4.6041 train_time:33777ms step_avg:293.71ms
step:250/3000 val_loss:4.1074 train_time:70705ms step_avg:294.61ms
step:375/3000 val_loss:3.9315 train_time:107428ms step_avg:294.32ms
step:500/3000 val_loss:3.8251 train_time:144389ms step_avg:294.67ms
step:625/3000 val_loss:3.7526 train_time:181315ms step_avg:294.82ms
step:750/3000 val_loss:3.7010 train_time:218031ms step_avg:294.64ms
step:875/3000 val_loss:3.6593 train_time:254967ms step_avg:294.76ms
step:1000/3000 val_loss:3.6215 train_time:291901ms step_avg:294.85ms
step:1125/3000 val_loss:3.5942 train_time:328599ms step_avg:294.71ms
step:1250/3000 val_loss:3.5674 train_time:365526ms step_avg:294.78ms
step:1375/3000 val_loss:3.5487 train_time:402443ms step_avg:294.83ms
step:1500/3000 val_loss:3.5252 train_time:439135ms step_avg:294.72ms
step:1625/3000 val_loss:3.5097 train_time:476083ms step_avg:294.79ms
step:1750/3000 val_loss:3.4935 train_time:513024ms step_avg:294.84ms
step:1875/3000 val_loss:3.4785 train_time:549739ms step_avg:294.77ms
step:2000/3000 val_loss:3.4645 train_time:586666ms step_avg:294.81ms
step:2125/3000 val_loss:3.4533 train_time:623614ms step_avg:294.85ms
step:2250/3000 val_loss:3.4275 train_time:660311ms step_avg:294.78ms
step:2375/3000 val_loss:3.4023 train_time:697267ms step_avg:294.83ms
step:2500/3000 val_loss:3.3780 train_time:734209ms step_avg:294.86ms
step:2625/3000 val_loss:3.3540 train_time:770928ms step_avg:294.81ms
step:2750/3000 val_loss:3.3331 train_time:807874ms step_avg:294.84ms
step:2875/3000 val_loss:3.3159 train_time:844800ms step_avg:294.87ms
step:3000/3000 val_loss:3.3055 train_time:881506ms step_avg:294.82ms
Peak memory consumption: 33530 MiB
