Training DataLoader: total tokens: 10255324043 in 103 files
Validation DataLoader: total tokens: 100000000 in 1 files
DeMon2 optimizer initialized with:
  - Learning rate: 0.04
  - Momentum factor (mu): 0.95
  - Residual factor (beta): 0.95
  - Weight decay: 0
  - Sparsity: 0.5
  - Newton-Schulz iterations: -1
  - Power iterations: 1
  - Epsilon: 1e-07
  - Tuned Newton-Schulz constants: False
  - Rank-r approximation method: power_iter
Training:   0%|          | 0/3000 [00:00<?, ?it/s][rank0]:W0312 14:04:48.744000 1382 site-packages/torch/_inductor/utils.py:1762] [0/0] DeviceCopy in input program
[rank0]:W0312 14:05:06.087000 1382 site-packages/torch/_inductor/utils.py:1762] [0/0] DeviceCopy in input program
[rank0]:W0312 14:05:08.888000 1382 site-packages/torch/_inductor/utils.py:1762] [0/0] DeviceCopy in input program
[rank0]:W0312 14:05:09.698000 1382 site-packages/torch/_inductor/utils.py:1762] [0/0] DeviceCopy in input program
[rank0]:W0312 14:05:10.715000 1382 site-packages/torch/_inductor/utils.py:1762] [0/0] DeviceCopy in input program
[rank0]:W0312 14:05:11.539000 1382 site-packages/torch/_inductor/utils.py:1762] [0/0] DeviceCopy in input program
[rank0]:W0312 14:05:12.323000 1382 site-packages/torch/_inductor/utils.py:1762] [0/0] DeviceCopy in input program
[rank0]:W0312 14:05:13.088000 1382 site-packages/torch/_inductor/utils.py:1762] [0/0] DeviceCopy in input program
[rank0]:W0312 14:05:13.856000 1382 site-packages/torch/_inductor/utils.py:1762] [0/0] DeviceCopy in input program

step:0/3000 val_loss:10.8258 train_time:5ms step_avg:nanms
Training:   0%|          | 0/3000 [00:49<?, ?it/s, val_loss=10.8258]/opt/conda/envs/ptca/lib/python3.10/site-packages/torch/_inductor/compile_fx.py:236: UserWarning: TensorFloat32 tensor cores for float32 matrix multiplication available but not enabled. Consider setting `torch.set_float32_matmul_precision('high')` for better performance.
  warnings.warn(
Training: 100%|██████████| 3000/3000 [16:39<00:00,  3.00it/s, val_loss=3.3123]   
step:125/3000 val_loss:4.5978 train_time:33630ms step_avg:292.43ms
step:250/3000 val_loss:4.1047 train_time:70450ms step_avg:293.54ms
step:375/3000 val_loss:3.9302 train_time:107001ms step_avg:293.15ms
step:500/3000 val_loss:3.8251 train_time:143849ms step_avg:293.57ms
step:625/3000 val_loss:3.7526 train_time:180703ms step_avg:293.83ms
step:750/3000 val_loss:3.7041 train_time:217246ms step_avg:293.58ms
step:875/3000 val_loss:3.6625 train_time:254093ms step_avg:293.75ms
step:1000/3000 val_loss:3.6264 train_time:290909ms step_avg:293.85ms
step:1125/3000 val_loss:3.5994 train_time:327451ms step_avg:293.68ms
step:1250/3000 val_loss:3.5730 train_time:364252ms step_avg:293.75ms
step:1375/3000 val_loss:3.5546 train_time:401091ms step_avg:293.84ms
step:1500/3000 val_loss:3.5356 train_time:437633ms step_avg:293.71ms
step:1625/3000 val_loss:3.5189 train_time:474453ms step_avg:293.78ms
step:1750/3000 val_loss:3.5001 train_time:511305ms step_avg:293.85ms
step:1875/3000 val_loss:3.4848 train_time:547829ms step_avg:293.74ms
step:2000/3000 val_loss:3.4721 train_time:584659ms step_avg:293.80ms
step:2125/3000 val_loss:3.4600 train_time:621479ms step_avg:293.84ms
step:2250/3000 val_loss:3.4343 train_time:658015ms step_avg:293.76ms
step:2375/3000 val_loss:3.4092 train_time:694861ms step_avg:293.81ms
step:2500/3000 val_loss:3.3843 train_time:731686ms step_avg:293.85ms
step:2625/3000 val_loss:3.3606 train_time:768211ms step_avg:293.77ms
step:2750/3000 val_loss:3.3400 train_time:805024ms step_avg:293.80ms
step:2875/3000 val_loss:3.3226 train_time:841868ms step_avg:293.85ms
step:3000/3000 val_loss:3.3123 train_time:878413ms step_avg:293.78ms
Peak memory consumption: 33530 MiB
